{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPreparing model:\\n - Install bazel ( check tensorflow's github for more info )\\n    Ubuntu 14.04:\\n        - Requirements:\\n            sudo add-apt-repository ppa:webupd8team/java\\n            sudo apt-get update\\n            sudo apt-get install oracle-java8-installer\\n        - Download bazel, ( https://github.com/bazelbuild/bazel/releases )\\n          tested on: https://github.com/bazelbuild/bazel/releases/download/0.2.0/bazel-0.2.0-jdk7-installer-linux-x86_64.sh\\n        - chmod +x PATH_TO_INSTALL.SH\\n        - ./PATH_TO_INSTALL.SH --user\\n        - Place bazel onto path ( exact path to store shown in the output)\\n- For retraining, prepare folder structure as\\n    - root_folder_name\\n        - class 1\\n            - file1\\n            - file2\\n        - class 2\\n            - file1\\n            - file2\\n- Clone tensorflow\\n\\nTraining:\\n- Go to root of tensorflow\\nbazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain\\nbazel-bin/tensorflow/examples/image_retraining/retrain --image_dir /home/ascend/Documents/perception/AscendDNN/DatabaseCreation/NewDatabase/Training --output_graph /home/ascend/Documents/perception/alexandria/output_graph.pb --output_labels /home/ascend/Documents/perception/alexandria/output_labels.txt --bottleneck_dir /home/ascend/Documents/perception/alexandria/bottleneck\\n\\nRun tensorboard\\npython tensorflow/tensorboard/tensorboard.py --logdir /home/ascend/Documents/perception/alexandria\\n\\nRunning:\\nbazel build tensorflow/examples/label_image:label_image && bazel-bin/tensorflow/examples/label_image/label_image --graph=/home/ascend/Documents/perception/alexandria/output_graph.pb --labels=/home/ascend/Documents/perception/alexandria/output_labels.txt --output_layer=final_result --image=/home/ascend/Documents/perception/data/green/2016-10-09-210940.jpg\\n\\n\\nFor testing through python, change and run this code.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preparing model:\n",
    " - Install bazel ( check tensorflow's github for more info )\n",
    "    Ubuntu 14.04:\n",
    "        - Requirements:\n",
    "            sudo add-apt-repository ppa:webupd8team/java\n",
    "            sudo apt-get update\n",
    "            sudo apt-get install oracle-java8-installer\n",
    "        - Download bazel, ( https://github.com/bazelbuild/bazel/releases )\n",
    "          tested on: https://github.com/bazelbuild/bazel/releases/download/0.2.0/bazel-0.2.0-jdk7-installer-linux-x86_64.sh\n",
    "        - chmod +x PATH_TO_INSTALL.SH\n",
    "        - ./PATH_TO_INSTALL.SH --user\n",
    "        - Place bazel onto path ( exact path to store shown in the output)\n",
    "- For retraining, prepare folder structure as\n",
    "    - root_folder_name\n",
    "        - class 1\n",
    "            - file1\n",
    "            - file2\n",
    "        - class 2\n",
    "            - file1\n",
    "            - file2\n",
    "- Clone tensorflow\n",
    "\n",
    "Training:\n",
    "- Go to root of tensorflow\n",
    "bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain\n",
    "bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir /home/ascend/Documents/perception/AscendDNN/DatabaseCreation/NewDatabase/Training --output_graph /home/ascend/Documents/perception/alexandria/output_graph.pb --output_labels /home/ascend/Documents/perception/alexandria/output_labels.txt --bottleneck_dir /home/ascend/Documents/perception/alexandria/bottleneck\n",
    "\n",
    "Run tensorboard\n",
    "python tensorflow/tensorboard/tensorboard.py --logdir /home/ascend/Documents/perception/alexandria\n",
    "\n",
    "Running:\n",
    "bazel build tensorflow/examples/label_image:label_image && \\\n",
    "bazel-bin/tensorflow/examples/label_image/label_image \\\n",
    "--graph=/home/ascend/Documents/perception/alexandria/output_graph.pb --labels=/home/ascend/Documents/perception/alexandria/output_labels.txt \\\n",
    "--output_layer=final_result \\\n",
    "--image=/home/ascend/Documents/perception/data/green/2016-10-09-210940.jpg\n",
    "\n",
    "\n",
    "For testing through python, change and run this code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:123: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "from math import sin, cos, radians\n",
    "#%matplotlib inline\n",
    "\n",
    "class Network:\n",
    "\n",
    "    #ef __init__(self, model, inputWidth, inputHeight, classes, load_preTrained_weights=True, \\\n",
    "    #   trained_w_epochs=0, trained_w_batch_size=0, trained_on_dataset=\"empty_set\", program_version=0):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.modelFullPath = '/home/ascend/Documents/perception/alexandria/output_graph.pb'\n",
    "        self.labelsFullPath = '/home/ascend/Documents/perception/alexandria/output_labels.txt'\n",
    "\n",
    "        self.full_image = np.asarray([])\n",
    "        self.input_image = np.asarray([])\n",
    "        self.found_targets_bounding_boxes = []\n",
    "\n",
    "        self.stoppedPropagationThread = False\n",
    "        \n",
    "        # Creates graph from saved GraphDef.\n",
    "        self.create_graph()\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.f = open(self.labelsFullPath, 'rb')\n",
    "        self.lines = self.f.readlines()\n",
    "        self.labels = [str(w).replace(\"\\n\", \"\") for w in self.lines]\n",
    "        \n",
    "        # assumtion of the world\n",
    "        #ystart = get_ystart()\n",
    "        self.ystart = 100\n",
    "        self.yend = self.get_yend()\n",
    "        self.ys = [y for y in range(self.ystart,self.yend+1)]\n",
    "        self.robotRadiuses = [self.pixel2robotRadius(y) for y in range(self.ystart,self.yend+1)]\n",
    "\n",
    "        print \"network initialized\"\n",
    "        \n",
    "\n",
    "    def create_graph(self):\n",
    "        \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "        # Creates graph from saved graph_def.pb.\n",
    "        with tf.gfile.FastGFile(self.modelFullPath, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    def run_inference_on_video(self):\n",
    "        answer = None\n",
    "        softmax_tensor = self.sess.graph.get_tensor_by_name('final_result:0')\n",
    "        predictions = self.sess.run(softmax_tensor, {'DecodeJpeg:0': self.input_image})\n",
    "        predictions = np.squeeze(predictions)\n",
    "        top_k = predictions.argsort()[-5:][::-1]  # Getting top 5 predictions\n",
    "\n",
    "        #for node_id in top_k:\n",
    "        #    human_string = labels[node_id]\n",
    "        #    score = predictions[node_id]\n",
    "        #    print('%s (score = %.5f)' % (human_string, score)),\n",
    "        #print \"\\n\"\n",
    "        answer = self.labels[top_k[0]]\n",
    "        return answer\n",
    "    \n",
    "    def pixel2scale(self, height, angle, pixel_y):\n",
    "        # returns number of meters one pixel width is on the ground\n",
    "        # F.ex if it returns 2, 10 pixels width is 20 meters on the ground\n",
    "\n",
    "        # Will return negative values if the pixel does not correspond to a point on the ground\n",
    "\n",
    "        # height from ground to camera in meters\n",
    "        # angle from downwards vector to camera center direction\n",
    "        # pixel y coordinate from top\n",
    "\n",
    "        #pinhole camera model\n",
    "        camera_ox = 640/2\n",
    "        camera_oy = 480/2\n",
    "        camera_focal = 1360.4/1080 * 480    \n",
    "\n",
    "        dy = pixel_y-camera_oy\n",
    "        dz = camera_focal\n",
    "\n",
    "        sa, ca = sin(radians(angle)), cos(radians(angle))\n",
    "        dz = ca*dz+sa*dy\n",
    "\n",
    "        t = height/dz\n",
    "        return t\n",
    "\n",
    "    def pixel2robotRadius(self, y):\n",
    "        return 0.33/self.pixel2scale(1, 70, y)\n",
    "\n",
    "    def get_ystart(self):\n",
    "        smallest_i = None\n",
    "        for i in range(480):\n",
    "            if self.pixel2robotRadius(i) > 0 and smallest_i == None:\n",
    "                smallest_i = i\n",
    "        return smallest_i\n",
    "\n",
    "    def get_yend(self):\n",
    "        yend = None\n",
    "        for y in range(self.ystart, 480):\n",
    "            if y + self.pixel2robotRadius(y) < 480:\n",
    "                yend = y\n",
    "        return yend\n",
    "    \n",
    "    def feed_full_image(self, img):\n",
    "        # non-blocking operation\n",
    "        self.full_image = img\n",
    "    \n",
    "    def search_image_for_targets(self):\n",
    "        self.found_targets_bounding_boxes = []\n",
    "        if self.full_image.size != 0:\n",
    "            print \"searching image\"\n",
    "            # blocking operation\n",
    "            for y, r in zip(self.ys,self.robotRadiuses):\n",
    "                pixel_width = len(self.full_image[0,:])\n",
    "                x_steps = int(pixel_width/r)\n",
    "                for x in range(0, pixel_width - int(r)):\n",
    "                    crop = self.full_image[y:y+r,x:x+r]\n",
    "                    self.input_image = cv2.resize(crop, (64,64))\n",
    "                    if self.run_inference_on_video() == 'robot':\n",
    "                        x1 = x\n",
    "                        y1 = y\n",
    "                        x2 = int(x+r)\n",
    "                        y2 = int(y+r)\n",
    "                        if not (x1,y1,x2,y2) in self.found_targets_bounding_boxes:\n",
    "                            self.found_targets_bounding_boxes.append((x1,y1,x2,y2))\n",
    "\n",
    "    def startPropagationThread(self):\n",
    "        t = Thread(target=self.propagateThread, args=())\n",
    "        t.daemon = True\n",
    "        print \"starting propagation thread\"\n",
    "        t.start()\n",
    "        return self\n",
    "\n",
    "    def propagateThread(self):\n",
    "        # keep looping infinitely until the thread is stopped\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the thread\n",
    "            if self.stoppedPropagationThread:\n",
    "                return\n",
    "            # otherwise, propagate\n",
    "            self.search_image_for_targets()\n",
    "\n",
    "    def stopPropagationThread(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        print \"stopping propagation thread\"\n",
    "        self.stoppedPropagationThread = True\n",
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        # initialize the video camera stream and read the first frame\n",
    "        # from the stream\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "        # initialize the variable used to indicate if the thread should\n",
    "        # be stopped\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        # start the thread to read frames from the video stream\n",
    "        t = Thread(target=self.update, args=())\n",
    "        t.daemon = True\n",
    "        print \"starting video stream thread\"\n",
    "        t.start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        # keep looping infinitely until the thread is stopped\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "\n",
    "            # otherwise, read the next frame from the stream\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        # return the frame most recently read\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        print \"stopping video stream thread\"\n",
    "        self.stopped = True\n",
    "        \n",
    "\n",
    "\n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "\n",
    "running_network = Network().startPropagationThread()\n",
    "\n",
    "running_capture = VideoStream(src=0).start() # varies\n",
    "\n",
    "while(True):\n",
    "    bgr_img = 0\n",
    "    bgr_img = running_capture.read()\n",
    "    img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    running_network.feed_full_image(img)\n",
    "    \n",
    "    targets = running_network.found_targets_bounding_boxes\n",
    "    \n",
    "    if targets:\n",
    "        for t in targets:\n",
    "            print \"found robot on \" + str(t[0]) + \" \" + str(t[1])\n",
    "            cv2.rectangle(bgr_img,(t[0],t[1]),(t[2],t[3]),(0,0,255),1)\n",
    "        \n",
    "    cv2.imshow('ImageWindow', bgr_img)\n",
    "    \n",
    "    k = cv2.waitKey(27)\n",
    "    if k == 27:\n",
    "        # stop the threads\n",
    "        running_capture.stop()\n",
    "        sleep(1)\n",
    "        running_network.stopPropagationThread()\n",
    "        sleep(1)\n",
    "        cv2.destroyAllWindows()\n",
    "        sleep(1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "running_capture.stop()\n",
    "sleep(1)\n",
    "running_network.stopPropagationThread()\n",
    "sleep(1)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "352\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371]\n"
     ]
    }
   ],
   "source": [
    "ys = [y for y in range(ystart,yend+1)]\n",
    "rs = [pixel2robotRadius(y) for y in range(ystart,yend+1)]\n",
    "print len(ys)\n",
    "print len(rs)\n",
    "\n",
    "print ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "371\n",
      "starting video stream thread\n",
      "stopping video stream thread\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from math import floor, ceil\n",
    "from math import sin, cos, radians\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import cv2\n",
    "from threading import Thread\n",
    "%matplotlib inline\n",
    "\n",
    "#pinhole camera model\n",
    "camera_ox = 640/2\n",
    "camera_oy = 480/2\n",
    "camera_focal = 1360.4/1080 * 480\n",
    "\n",
    "def pixel2scale(height, angle, pixel_y):\n",
    "    # returns number of meters one pixel width is on the ground\n",
    "    # F.ex if it returns 2, 10 pixels width is 20 meters on the ground\n",
    "\n",
    "    # Will return negative values if the pixel does not correspond to a point on the ground\n",
    "\n",
    "    # height from ground to camera in meters\n",
    "    # angle from downwards vector to camera center direction\n",
    "    # pixel y coordinate from top\n",
    "    \n",
    "    dy = pixel_y-camera_oy\n",
    "    dz = camera_focal\n",
    "\n",
    "    sa, ca = sin(radians(angle)), cos(radians(angle))\n",
    "    dz = ca*dz+sa*dy\n",
    "\n",
    "    t = height/dz\n",
    "    return t\n",
    "\n",
    "def pixel2robotRadius(y):\n",
    "    return 0.33/pixel2scale(1, 70, y)\n",
    "\n",
    "def get_ystart():\n",
    "    smallest_i = None\n",
    "    for i in range(480):\n",
    "        if pixel2robotRadius(i) > 0 and smallest_i == None:\n",
    "            smallest_i = i\n",
    "    return smallest_i\n",
    "\n",
    "def get_yend():\n",
    "    yend = None\n",
    "    for y in range(ystart, 480):\n",
    "        if y + pixel2robotRadius(y) < 480:\n",
    "            yend = y\n",
    "    return yend\n",
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        # initialize the video camera stream and read the first frame\n",
    "        # from the stream\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "        # initialize the variable used to indicate if the thread should\n",
    "        # be stopped\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        # start the thread to read frames from the video stream\n",
    "        t = Thread(target=self.update, args=())\n",
    "        t.daemon = True\n",
    "        print \"starting video stream thread\"\n",
    "        t.start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        # keep looping infinitely until the thread is stopped\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "\n",
    "            # otherwise, read the next frame from the stream\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        # return the frame most recently read\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        print \"stopping video stream thread\"\n",
    "        self.stopped = True\n",
    "\n",
    "ystart = get_ystart()\n",
    "yend = get_yend()\n",
    "\n",
    "print ystart\n",
    "print yend\n",
    "\n",
    "running_capture = VideoStream(src=0).start() # varies\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "bgr_img = running_capture.read()\n",
    "img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "running_capture.stop()\n",
    "sleep(1)\n",
    "\n",
    "# assumtion of the world\n",
    "ys = [y for y in range(ystart,yend+1)]\n",
    "robotRadiuses = [pixel2robotRadius(y) for y in range(ystart,yend+1)]\n",
    "#print robotRadiuses\n",
    "for y, r in zip(ys,robotRadiuses):\n",
    "    #if y < 1:\n",
    "    #    pass\n",
    "    pixel_width = len(img[0,:])\n",
    "    x_steps = int(pixel_width/r)\n",
    "    #print x_steps\n",
    "    #print floor(x_steps)\n",
    "    #print type(x_steps)\n",
    "    #sys.exit()\n",
    "    #for x in range(x_steps):\n",
    "    for x in range(0, pixel_width - int(r)):\n",
    "        #print y\n",
    "        #print x\n",
    "        #temp = img[y*r:y*r+r,x*r:x*r+r]\n",
    "        #print temp.shape\n",
    "        #center_x = x*r + (x*r+r - x*r)/2\n",
    "        #center_y = y*r + (y*r+r - y*r)/2\n",
    "        #portions[(center_x,center_y)] = temp\n",
    "        \n",
    "        if run_inference_on_video(img, sess, labels) == \"robot\":\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = int(x+r)\n",
    "            y2 = int(y+r)\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),1)\n",
    "\n",
    "#cv2.rectangle(img,(0,200),(150,400),(255,0,0),1)\n",
    "\n",
    "cv2.imshow('original',bgr_img)\n",
    "cv2.imshow('with search windows',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    portions = []\n",
    "    y_steps = len(img[:,0])/64\n",
    "    x_steps = len(img[0,:])/64\n",
    "    for y in range(y_steps):\n",
    "        for x in range(x_steps):\n",
    "            #print y\n",
    "            #print x\n",
    "            temp = img[y*64:y*64+64,x*64:x*64+64]\n",
    "            #print temp.shape\n",
    "            portions.append(temp)\n",
    "            #cv2.imshow('ImageWindow', temp)\n",
    "    \n",
    "    if False:\n",
    "        plt.ion()\n",
    "        for i in range(len(portions)):   \n",
    "            plt.subplot(y_steps,x_steps,i+1)\n",
    "            take = portions[i]\n",
    "            plt.imshow(take)\n",
    "        plt.show()\n",
    "        plt.pause(0.05)\n",
    "    if False:\n",
    "        for i in range(len(portions)):\n",
    "            take = portions[i]\n",
    "            #norm = take/255.0\n",
    "            #print run_inference_on_video(take, sess, labels)\n",
    "\n",
    "    #cv2.imwrite(\"/home/ascend/Desktop/temp.jpg\", res)stream thread\"\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VideoStream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-13b446ef6dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/dev/stdout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrunning_capture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# varies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# assumtion of the world\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VideoStream' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "running_capture = VideoStream(src=1).start() # varies\n",
    "\n",
    "# assumtion of the world\n",
    "ys = [y for y in range(ystart,yend+1)]\n",
    "robotRadiuses = [pixel2robotRadius(y) for y in range(ystart,yend+1)]\n",
    "\n",
    "while(True):\n",
    "    bgr_img = running_capture.read()\n",
    "    \n",
    "    img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "    portions = {}\n",
    "    for y, r in zip(ys,robotRadiuses):\n",
    "        x_steps = len(img[0,:])/r\n",
    "        for x in range(x_steps):\n",
    "            #print y\n",
    "            #print x\n",
    "            #temp = img[y*r:y*r+r,x*r:x*r+r]\n",
    "            #print temp.shape\n",
    "            #center_x = x*r + (x*r+r - x*r)/2\n",
    "            #center_y = y*r + (y*r+r - y*r)/2\n",
    "            #portions[(center_x,center_y)] = temp\n",
    "            #cv2.imshow('ImageWindow', temp)\n",
    "            pass\n",
    "    \n",
    "    #img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "    #cv2.rectangle(bgr_img,(0,0),(200,100),(0,0,255),3)\n",
    "    cv2.imshow('ImageWindow', bgr_img)\n",
    "    \n",
    "    k = cv2.waitKey(27)\n",
    "    if k == 27:\n",
    "        # stop the threads\n",
    "        running_capture.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        sleep(0.1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "running_capture = VideoStream(src=0).start() # varies\n",
    "\n",
    "running_capture.stop()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def run_inference_on_image():\n",
    "    answer = None\n",
    "\n",
    "    if not tf.gfile.Exists(self.imagePath):\n",
    "        tf.logging.fatal('File does not exist %s', self.imagePath)\n",
    "        return answer\n",
    "\n",
    "    image_data = tf.gfile.FastGFile(self.imagePath, 'rb').read()\n",
    "\n",
    "    # Creates graph from saved GraphDef.\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                               {'DecodeJpeg/contents:0': image_data})\n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        top_k = predictions.argsort()[-5:][::-1]  # Getting top 5 predictions\n",
    "        f = open(self.labelsFullPath, 'rb')\n",
    "        lines = f.readlines()\n",
    "        labels = [str(w).replace(\"\\n\", \"\") for w in lines]\n",
    "        for node_id in top_k:\n",
    "            human_string = labels[node_id]\n",
    "            score = predictions[node_id]\n",
    "            print('%s (score = %.5f)' % (human_string, score))\n",
    "\n",
    "        answer = labels[top_k[0]]\n",
    "        return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
